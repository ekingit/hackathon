{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyMSCyAkyqqIOcc6b/O7S52g",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ekingit/hackathon/blob/main/train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "twnPmIg60BBD",
        "outputId": "7bc6aad0-c1af-422b-d5b6-c3c084f0169f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
        "from itertools import chain\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data, Model, Train"
      ],
      "metadata": {
        "id": "8XG9fSP5DtrP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Data(Dataset):\n",
        "    def __init__(self, path, person_start, person_end, window_len):\n",
        "        super().__init__()\n",
        "\n",
        "        self.window_len = window_len\n",
        "        df = pd.read_csv(path)\n",
        "        person_ids = [str(i) for i in range(person_start,person_end)]\n",
        "        if '2660' in person_ids:\n",
        "            person_ids.remove('2660')\n",
        "        self.df_person = df[person_ids]\n",
        "\n",
        "        dataset = torch.tensor(self.df_person.values,dtype = torch.float)\n",
        "        self.mean = dataset.mean(dim=0)\n",
        "        self.std = dataset.std(dim=0)\n",
        "        self.dataset = (dataset - self.mean)/self.std\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        tens = self.dataset[index:index+self.window_len]\n",
        "        return tens\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset) - self.window_len"
      ],
      "metadata": {
        "id": "pYIeRvc70IEC"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class local_LSTM(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers):\n",
        "        super().__init__()\n",
        "        self.gru = nn.GRU(input_size, hidden_size, num_layers,batch_first=True)\n",
        "    def forward(self, X, H):#X=(batch_size,seq_len, num_features),H,c=(num_layers,batch_size,hidden_size)\n",
        "        X, H = self.gru(X, H) #X=(batch_size,seq_len,num_features)\n",
        "        return X, H\n",
        "\n",
        "class linear_layer(nn.Module):\n",
        "    def __init__(self, input_size,output_size):\n",
        "        super().__init__()\n",
        "        self.linear = nn.Linear(input_size,output_size)\n",
        "        self.act = nn.ReLU()\n",
        "    def forward(self, X):\n",
        "      X = self.linear(X)\n",
        "      return X"
      ],
      "metadata": {
        "id": "OaQ3xLiP0NYC"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def autoregressive(X, model_enc, model_dec, H, washout, seq_len, window_len):\n",
        "    X_in = X[:,:seq_len,:]#X_in.shape=(batch_size,seq_len,input_size)\n",
        "    X_out, H = model_enc(X_in, H)\n",
        "    X_out = model_dec(X_out) #X_out.shape=(batch_size,seq_len,input_size)\n",
        "    Y_hat = []\n",
        "    Y_hat.append(X_out[:,washout:])#Y_hat.shape=(batch_size,seq_len-washout,50)\n",
        "    for i in range(window_len-seq_len-1):\n",
        "      X_in = X_out[:,-1,:].unsqueeze(1) #(batch_size,1,50)\n",
        "      X_out, H = model_enc(X_in, H)\n",
        "      X_out = model_dec(X_out)\n",
        "      Y_hat.append(X_out)\n",
        "    Y_hat = torch.cat(Y_hat,1).squeeze(-1)\n",
        "    return Y_hat #(batch_size,window_len-washout-1)\n",
        "\n",
        "\n",
        "def train(model1, model2, num_layers, hidden_size, dl, seq_len, window_len, washout, optimizer, loss_fn, device):\n",
        "    model1.to(device)\n",
        "    model2.to(device)\n",
        "    model1.train()\n",
        "    model2.train()\n",
        "    train_loss = 0\n",
        "    for X in dl:\n",
        "        X = X.to(device)\n",
        "        Y_hat = []\n",
        "        optimizer.zero_grad()\n",
        "        H = torch.zeros(num_layers,X.shape[0], hidden_size,device=device)\n",
        "        Y_hat = autoregressive(X, model1, model2, H, washout, seq_len, window_len)\n",
        "        Y = X[:,washout+1:,:] #(batch_size,window_len-washout-1)\n",
        "        loss = loss_fn(Y_hat, Y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()\n",
        "    train_loss = train_loss/(len(dl.dataset)*(window_len-washout-1))\n",
        "    return train_loss"
      ],
      "metadata": {
        "id": "MfKLOQM-0JQZ"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run!"
      ],
      "metadata": {
        "id": "qV0r1SjQDzNI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#params\n",
        "input_size = 4124\n",
        "hidden_size = 2048\n",
        "num_layers = 2\n",
        "seq_len = 24*4\n",
        "washout = 0\n",
        "window_len = 24*5\n",
        "lr = 1e-3\n",
        "batch_size = 64"
      ],
      "metadata": {
        "id": "g-MHqisf0OfR"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/drive/MyDrive/hackathon/smart_meters_london_2013.csv'\n",
        "data = Data(path,0,input_size+1,window_len)\n",
        "dl = DataLoader(data, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "encoder = local_LSTM(input_size, hidden_size,num_layers)\n",
        "decoder = linear_layer(hidden_size,input_size)\n",
        "\n",
        "encoder_params = encoder.parameters()\n",
        "decoder_params = decoder.parameters()\n",
        "all_params = chain(encoder_params, decoder_params)\n",
        "optimizer = torch.optim.Adam(all_params, lr)\n",
        "loss_fn = nn.MSELoss(reduction='sum')\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "encoder.to(device)\n",
        "decoder.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IqM_YBzs0PmZ",
        "outputId": "2a2b206f-49e2-4b2b-e4cd-86f62d4da8f2"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "linear_layer(\n",
              "  (linear): Linear(in_features=2048, out_features=4124, bias=True)\n",
              "  (act): ReLU()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_loss = 5000\n",
        "for epoch in range(20):\n",
        "  train_loss = train(encoder,decoder, num_layers, hidden_size, dl, seq_len, window_len, washout, optimizer, loss_fn, device)\n",
        "  print(train_loss)\n",
        "  if train_loss < best_loss:\n",
        "    best_loss = train_loss\n",
        "    torch.save(encoder.state_dict(), '/content/drive/MyDrive/hackathon/encoder_scaled4.pth')\n",
        "    torch.save(decoder.state_dict(), '/content/drive/MyDrive/hackathon/decoder_scaled4.pth')"
      ],
      "metadata": {
        "id": "K4AbBjpN0uF4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ab9bad1-9238-46a1-a583-cb9de53176d8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2892.8223097572363\n",
            "2266.920084422658\n",
            "1878.7560700669158\n",
            "1663.8306216931217\n",
            "1358.9469975490197\n",
            "1657.1610255213197\n",
            "2096.399960122938\n",
            "1456.9891583022097\n",
            "1268.1685340802987\n",
            "1150.442287192655\n",
            "1067.1647180399939\n",
            "1000.6438278089014\n",
            "4215.9065301120445\n",
            "3980.6620117491443\n",
            "6232.850914254591\n",
            "105922.0692071273\n",
            "395051.96809835045\n",
            "611630.621101774\n",
            "500458.3158418923\n",
            "465349.9376283847\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#smaller model"
      ],
      "metadata": {
        "id": "tqzpbfaIDowm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#params\n",
        "input_size = 4124\n",
        "hidden_size = 2048\n",
        "num_layers = 1\n",
        "seq_len = 24*4\n",
        "washout = 0\n",
        "window_len = 24*5\n",
        "lr = 1e-3\n",
        "batch_size = 64"
      ],
      "metadata": {
        "id": "qE-AEsGT_Fpc"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_loss = 5000\n",
        "for epoch in range(20):\n",
        "  train_loss = train(encoder,decoder, num_layers, hidden_size, dl, seq_len, window_len, washout, optimizer, loss_fn, device)\n",
        "  print(train_loss)\n",
        "  if train_loss < best_loss:\n",
        "    best_loss = train_loss\n",
        "    torch.save(encoder.state_dict(), '/content/drive/MyDrive/hackathon/encoder_scaled.pth')\n",
        "    torch.save(decoder.state_dict(), '/content/drive/MyDrive/hackathon/decoder_scaled.pth')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "id": "Z8EpNLC6-4j_",
        "outputId": "b7a1f637-4eca-4451-b07d-7fcc3bd22fbd"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2906.7991013071896\n",
            "2177.394508636788\n",
            "1834.5383986928105\n",
            "2303.1292960239653\n",
            "1678.19302054155\n",
            "1744.1855547774665\n",
            "1542.7292678182384\n",
            "32720.909030695613\n",
            "658092.2163709928\n",
            "586571.8916900094\n",
            "555595.1873015873\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-fecdefb69adf>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mbest_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_layers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwashout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtrain_loss\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mbest_loss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-9c7de930647b>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model1, model2, num_layers, hidden_size, dl, seq_len, window_len, washout, optimizer, loss_fn, device)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdl\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mY_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    699\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    755\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    758\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    396\u001b[0m         \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Handle `CustomType` automatically\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m     \"\"\"\n\u001b[0;32m--> 398\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcollate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefault_collate_fn_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcollate_fn_map\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0melem_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0melem_type\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcollate_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mcollate_tensor_fn\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_typed_storage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_shared\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "59ZOzWEh_If8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}